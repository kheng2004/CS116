{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddd1935-6fd3-4d1a-aac0-ed9d8bc41e30",
   "metadata": {},
   "source": [
    "\n",
    "# TIỀN XỬ LÝ DỮ LIỆU (PHẦN 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa6559-78de-4138-9cc7-a5fb933f1edd",
   "metadata": {},
   "source": [
    "Trong lĩnh vực machine learning, việc tiền xử lý dữ liệu đóng vai trò quan trọng để xây dựng những mô hình chính xác và mạnh mẽ. Dữ liệu thô thường gặp phải tình trạng lộn xộn, thiếu sót và không nhất quán. Tiền xử lý dữ liệu bao gồm một loạt các kỹ thuật và nhiệm vụ nhằm biến đổi và tinh chỉnh dữ liệu thô thành một định dạng thích hợp, chuẩn bị cho việc phân tích và huấn luyện mô hình.\n",
    "\n",
    "Bằng cách giải quyết các vấn đề như giá trị thiếu, các ngoại lệ và tỷ lệ biến đổi khác nhau, việc tiền xử lý đảm bảo chất lượng dữ liệu được cải thiện, dẫn đến hiệu suất mô hình cải thiện.\n",
    "\n",
    "Trong cuốn sổ tay Jupyter này, chúng ta sẽ đào sâu vào các bước cơ bản của tiền xử lý dữ liệu. Chúng ta sẽ làm việc thông qua một bài tập thực tế bằng Python, nơi chúng ta sẽ tập trung vào 2 nhiệm vụ cơ bản:\n",
    "\n",
    "* Xác định và xử lý giá trị bị thiếu\n",
    "* Chuẩn hóa dữ liệu\n",
    "\n",
    "Khi kết thúc bài tập này, bạn sẽ đã có được kinh nghiệm thực tế trong việc đánh giá, làm sạch và biến đổi dữ liệu thô thành một định dạng thích hợp cho việc học máy. Những kỹ năng này là nền tảng trong hành trình khoa học dữ liệu, vì chúng đặt ra sân khấu cho các kỹ thuật nâng cao hơn và việc xây dựng mô hình. Vậy thì, hãy bắt đầu và học nghệ thuật tiền xử lý dữ liệu để mở khóa tiềm năng thực sự của những nỗ lực trong lĩnh vực học máy của bạn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd834d8-e341-45cb-a9a4-dadeb465c73e",
   "metadata": {},
   "source": [
    "### 1. Tải dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbec23-831c-4bd5-972c-e23702f7a448",
   "metadata": {},
   "source": [
    "Dữ liệu được sử dụng sẽ là dữ liệu về giá nhà, cụ thể như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d08ee2f-9d4e-4644-83b7-6370af18e368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0          NaN           129.0   \n",
       "1        NaN     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                 NaN          NaN           190.0   \n",
       "3    -122.25     37.85                 NaN          NaN           235.0   \n",
       "4    -122.25       NaN                52.0          NaN           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0         NaN         NaN         8.3252            452600.0  \n",
       "1         NaN         NaN         8.3014            358500.0  \n",
       "2         NaN         NaN         7.2574            352100.0  \n",
       "3         NaN         NaN         5.6431            341300.0  \n",
       "4       565.0       259.0         3.8462            342200.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"./data/housing.csv\"\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df_test = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec78eff-052e-498c-88a2-6e9745e62276",
   "metadata": {},
   "source": [
    "### 2. Xác định số phần tử bị thiếu ở mỗi cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53e6cfa-14cd-4951-b811-dd5176d30f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude              6826\n",
       "latitude               5020\n",
       "housing_median_age     7711\n",
       "total_rooms           13089\n",
       "total_bedrooms          432\n",
       "population            13206\n",
       "households            15149\n",
       "median_income          2145\n",
       "median_house_value     5227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liệt kê số phần tử bị thiếu ở mỗi cột\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60474ab-3789-4d3b-aaaa-3c2a6740bd8e",
   "metadata": {},
   "source": [
    "### 3. Loại bỏ những cột có nhiều giá trị bị thiếu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb16d5d-ddc2-4be4-a96c-d9803d9430d0",
   "metadata": {},
   "source": [
    "**Bài tập**: Hãy viết hàm nhận vào `dataframe` và `threshold` (ngưỡng phần trăm).\n",
    "Trả về `dataframe` mới sau khi đã loại bỏ hết tất cả các cột mà tỉ lệ phần\n",
    "trăm giá trị bị thiếu vượt qua `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522f6c21-9220-4f04-b125-6a88dba3d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(df: pd.DataFrame, threshold: float) -> pd.DataFrame:\n",
    "\n",
    "    missing_ratio = df.isnull().mean()   \n",
    "    cols_to_drop = missing_ratio[missing_ratio > threshold].index  \n",
    "    return df.drop(columns=cols_to_drop)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0128b-67c9-47d0-a996-5052b3be2612",
   "metadata": {},
   "source": [
    "Ta tiến hành loại bỏ những cột có nhiều giá trị bị thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c8488a-9dc4-4bdc-a446-b6748afbd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nếu cột có phần trăm giá trị bị thiếu > 60% thì sẽ bị loại bỏ\n",
    "threshold = 0.6\n",
    "df = drop_sparse_columns(df, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee09c860-0a27-4925-b864-bd5f079d3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra với public tests\n",
    "assert df.shape[1] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c64ab224-9b36-433d-ac62-261beafb020d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             6826\n",
       "latitude              5020\n",
       "housing_median_age    7711\n",
       "total_bedrooms         432\n",
       "median_income         2145\n",
       "median_house_value    5227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sau khi đã loại bỏ những cột không cần thiết do chứa quá nhiều giá trị bị thiếu\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9d895-83bf-4085-a3eb-6fa6c8fb522c",
   "metadata": {},
   "source": [
    "### 4. Lắp đầy những giá trị thiếu ở những cột còn lại"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18320f5-2387-4497-8a37-e28f56c9074f",
   "metadata": {},
   "source": [
    "**Bài tập**: Hãy viết các hàm thực hiện điền giá trị bị thiếu vào `dataframe` ứng với\n",
    "với các chiến lược sau: ***min imputation***, ***max imputation***, ***mean imputation***, ***zero imputation***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "febb7fb7-16bb-4c5f-8ae3-b6573bf4ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_test(df: pd.DataFrame, scaler) -> pd.DataFrame:\n",
    "    scaled_data = df.apply(lambda col:\n",
    "                           scaler.fit_transform(col.values.reshape(-1, 1)).flatten())\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    return scaled_df\n",
    "    pass\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "def fill_with_min(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    return df.fillna(df.min())\n",
    "    ### END SOLUTION\n",
    "   \n",
    "\n",
    "def fill_with_max(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    return df.fillna(df.max())\n",
    "    ### END SOLUTION\n",
    "\n",
    "def fill_with_mean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    return df.fillna(df.mean())\n",
    "    ### END SOLUTION\n",
    "\n",
    "\n",
    "def fill_with_zero(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    return df.fillna(0)\n",
    "    ### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6da81d-b460-41aa-a155-da24cd5a521a",
   "metadata": {},
   "source": [
    "Ta gọi hàm và tạo những `dataframe` mới ứng với từng kiểu điền rỗng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c7906b-66a6-4056-a910-abfccdb7b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_filled_df = fill_with_min(df)\n",
    "max_filled_df = fill_with_max(df)\n",
    "mean_filled_df = fill_with_mean(df)\n",
    "zero_filled_df = fill_with_zero(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8443dad-0d6e-4014-9c61-077e444fc27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra với public tests\n",
    "assert not min_filled_df.isna().any().any()\n",
    "assert not max_filled_df.isna().any().any()\n",
    "assert not mean_filled_df.isna().any().any()\n",
    "assert not zero_filled_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925d3ac-0022-4af7-88f6-383e7151ff63",
   "metadata": {},
   "source": [
    "## 4. Chuẩn hóa dữ liệu\n",
    "Các đặc trưng thường đi kèm với các tỷ lệ biến đổi khác nhau, điều này có thể dẫn đến mô hình thiên vị. Chúng ta sẽ khám phá các kỹ thuật chuẩn hóa phổ biến\n",
    "\n",
    "- Min-Max Scaling: Nó biến đổi các giá trị trong tập dữ liệu về các giá trị trong khoảng từ 0 đến 1.\n",
    "$$ x_{scaled} = {x-x_{min} \\over x_{max} - x_{min}} $$\n",
    "\n",
    "\n",
    ">>>| x | $x_{scaled}$ |\n",
    "|:--------:|:--------:|\n",
    "| 10       | 0.0      |\n",
    "| -20       | 0.5      |\n",
    "| 35       | 0.25      |\n",
    "| 48       | 1.0      |\n",
    "| 53       | 0.75      |\n",
    "\n",
    "- Standard Scaling (Z-score normalization): Nó tính toán giá trị trung bình và độ lệch chuẩn của tập dữ liệu và chuẩn hóa nó bằng cách trừ giá trị trung bình và chia cho độ lệch chuẩn.\n",
    "\n",
    "$$ x_{scaled} = {x- mean_x \\over std_x} $$\n",
    "\n",
    ">>>| x | $x_{scaled}$ |\n",
    "|:--------:|:--------:|\n",
    "| 10       | -0.56     |\n",
    "| -20       | -1.67      |\n",
    "| 35       | 0.36      |\n",
    "| 48       | 0.84     |\n",
    "| 53       | 1.03      |\n",
    "\n",
    " >>>$mean_x=$25.2, $std_x \\approx$27.0658\n",
    "\n",
    " >>>$mean_{x_{scaled}} \\approx$0, $std_{x_{scaled}} \\approx$1\n",
    "\n",
    "- Robust Scaling: RobustScaler là một kỹ thuật sử dụng trung vị và quartiles để giải quyết các bias từ các giá trị ngoại lệ.\n",
    "\n",
    "$$ x_{scaled} = {x-x_{median} \\over x_{75} - x_{25}} $$\n",
    "\n",
    ">>>| x | $x_{scaled}$ |\n",
    "|:--------:|:--------:|\n",
    "| 10       | -0.66     |\n",
    "| -20       | -1.45      |\n",
    "| 35       | 0.0      |\n",
    "| 48       | 0.34     |\n",
    "| 53       | 0.47      |\n",
    "\n",
    "![anh](https://i.imgur.com/MARX2bg.png)\n",
    "\n",
    " Những kỹ thuật này sẽ giúp đưa các đặc trưng về một tỷ lệ chung, ngăn chặn bất kỳ đặc trưng nào chiếm ưu thế trong quá trình học."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb86ede-ee1f-4c5e-a16f-9d2558b5dd20",
   "metadata": {},
   "source": [
    "**Bài tập**: Hãy viết hàm nhận vào `dataframe` và một `object` thuộc một trong ba\n",
    "scaler đã được import bên dưới và trả vể dataframe đã được chuẩn hóa sử dụng scaler đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "206f1588-acf6-4cdb-8565-e3c349d8b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng các class scaler có từ thư viện sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94c918f3-0a71-4945-9db6-478ed2b617bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Column1\n",
      "0 -0.657895\n",
      "1 -1.447368\n",
      "2  0.000000\n",
      "3  0.342105\n",
      "4  0.473684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tạo DataFrame với một cột dữ liệu\n",
    "data = {'Column1': [10, -20, 35, 48, 53]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Khởi tạo StandardScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Áp dụng StandardScaler vào cột dữ liệu\n",
    "scaled_data = df.apply(lambda col: scaler.fit_transform(col.values.reshape(-1, 1)).flatten())\n",
    "\n",
    "# In kết quả\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0317f552-9f24-426d-8565-ecda9520f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df: pd.DataFrame, scaler) -> pd.DataFrame:\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    scaled_dt = df.apply(lambda col: scaler.fit_transform(col.values.reshape(-1, 1)).flatten())\n",
    "    return scaled_dt\n",
    "\n",
    "\n",
    "    ### END SOLUTION\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d89fa-da38-450c-9768-07b9bcfc9abc",
   "metadata": {},
   "source": [
    "Tiến hành tạo các `dataframe` ứng với từng kiểu chuẩn hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "101f21b9-6772-432f-8500-ed9dbcaba669",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaled_df = scale(mean_filled_df, MinMaxScaler())\n",
    "standard_scaled_df = scale(mean_filled_df, StandardScaler())\n",
    "robust_scaled_df = scale(mean_filled_df, RobustScaler())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
